{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c7383-5c69-4a68-b997-a4bfd3a42af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import iglob, glob\n",
    "from downloader import api\n",
    "from downloader.wikidata import get_orcid_to_commons_image, get_orcid_to_wikidata\n",
    "from functools import partial\n",
    "import os\n",
    "import pandas as pd\n",
    "def gen_record(rec, affil,ty):\n",
    "    return {\"orcid\": rec.orcid,\n",
    "             \"name\": rec.name,\n",
    "             \"type\": ty,\n",
    "             \"org_name\": affil.name,\n",
    "             \"role\": affil.role,\n",
    "             \"country\": affil.country,\n",
    "             \"department_name\": affil.department,\n",
    "             \"start_year\": affil.start.year if affil.start else None,\n",
    "             \"end_year\": affil.end.year if affil.end else None\n",
    "            }\n",
    "\n",
    "\n",
    "def iter_dir(dirname):\n",
    "    \n",
    "    output_name = f\"/data/orcid/summ_out/{os.path.basename(dirname)}\"\n",
    "    if os.path.exists(f\"{output_name}_affiliations.parquet\"):\n",
    "        print(f\"found {output_name}, done\")\n",
    "        return\n",
    "    \n",
    "    it = glob(f\"{dirname}/*\")\n",
    "    f = partial(\n",
    "        api.process_file,\n",
    "        orcid_to_wikidata=None,\n",
    "        orcid_to_wikimedia_commons=None\n",
    "    )\n",
    "    \n",
    "    print(f\"Globbing {dirname}, {len(it)}, {output_name}\")\n",
    "    \n",
    "    affiliations = []\n",
    "    n_affil = []\n",
    "    empty = []\n",
    "    for i, file in enumerate(it):\n",
    "        try:\n",
    "            record: api.Record | None = f(file)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        if not record:\n",
    "            empty.append(file)\n",
    "            continue\n",
    "        n_rec = 0\n",
    "        for employment in record.employments:\n",
    "            n_rec +=1\n",
    "            affiliations.append(gen_record(record, employment,\"employment\"))\n",
    "        for ed in record.educations:\n",
    "            n_rec +=1\n",
    "            affiliations.append(gen_record(record, ed,\"education\"))\n",
    "        for inv in record.invited_positions:\n",
    "            n_rec +=1\n",
    "            affiliations.append(gen_record(record, inv,\"invited\"))\n",
    "        n_affil.append({\"oid\":record.orcid,\"file\": file, \"n_rec\":n_rec})\n",
    "    pd.DataFrame(affiliations).to_parquet(f\"{output_name}_affiliations.parquet\")\n",
    "    pd.DataFrame(n_affil).to_parquet(f\"{output_name}_naffil.parquet\")\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "dirs = glob(\"/data/orcid/ORCID_2025_10_summaries/*\")\n",
    "from multiprocess import Pool\n",
    "max_pool = 12\n",
    "\n",
    "with Pool(max_pool) as p:\n",
    "    pool_outputs = list(\n",
    "        #tqdm(\n",
    "            p.map(iter_dir,dirs)#,\n",
    "            #total=len(dirs)\n",
    "        #)\n",
    "    )    \n",
    "\n",
    "print(pool_outputs)\n",
    "new_dict = dict(pool_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orcid",
   "language": "python",
   "name": "orcid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
